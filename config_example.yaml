# Paper Loupe Configuration Example
# Copy this file to ~/.config/paper-loupe/config.yaml and modify as needed

# Questions to evaluate paper relevance against
questions:
  - "What are the latest advancements in multimodal large language models?"
  - "How are fundamental changes to the transformer architecture allowing for more efficient training or inference?"
  - "What are recent developments in efficient training for large language models?"
  - "How are transformers being used for multiview diffusion and generative 3D tasks?"

# API keys for LLM providers
# You can set these as environment variables instead:
# PAPER_LOUPE_OPENAI_API_KEY, PAPER_LOUPE_ANTHROPIC_API_KEY
api_keys:
  # OpenAI API key (required for OpenAI models)
  openai: ""  # Replace with your actual API key

  # Anthropic API key (required for Claude models)
  anthropic: ""  # Replace with your actual API key if using Claude models

# Optional settings
settings:
  # Default model to use for relevance scoring (optional)
  default_model: "gpt-4o-mini"

  # Default output path for ranked papers (optional)
  # If not specified, results will only be printed to the console
  # default_output_path: "~/paper_rankings.csv"
